\documentclass[a4paper, 12pt]{article}
\input{commandspreamble.tex}
\usepackage{tabularx}

\title{Code documentation}
\author{C\'esar Garro-Mar\'in\thanks{Boston University, email: \href{mailto:cesarlgm@bu.edu}{cesarlgm@bu.edu}}} 

\begin{document}
\maketitle
\section{Notation}
Our GMM model is based on the moment equations:
\beqns
\expect{\psi(w_i,\mu)}{}=0	
\eeqns
where:
\bitem
\item $w_i$ is the vector of data for observation $i$.
\item $\psi$ is a $P\times 1$ vector of functions.
\item $\mu$ is an $R\times 1$ vector of parameters. 
\eitem 


We estimate the model's parameters $\mu$ by solving he problem:
\beqns
\hat{\mu}=\arg\min_c\left(\frac{1}{N}\sum_{i=1}^{N}\psi(w_i,c)\right)'A\left(\frac{1}{N}\sum_{i=1}^{N}\psi(w_i,c)\right)
\eeqns
which we can write as:
\beqns
\hat{\mu}=\arg\min_c\left(\frac{1}{N}\varepsilon(c)'Z\right)A\left(\frac{1}{N}Z'\varepsilon(c)\right)
\eeqns
where $\varepsilon(c)$ is the $N\times 1$ vector of errors of the model, and $Z$ is the $N\times P$ matrix of instruments. Here $N=N_1+N_2+N_3$ is the total number of observations and $N_i$ denotes the number of observations that belong to equation $i$. 

$\varepsilon(c)$ is defined as follows. Define the functions $J(l)$, $E(l)$, $T(l)$, and $I(l)$ which return the job, education level, year, and skill that correspond to observation $l$. In addition, for observations belonging to the employment equation, define as $EET(l)$ as the function that returns the education pair-year cell of the observation. Then the error for observation $l$ is:
\beqns
\varepsilon_l(\mu)=\left\{\begin{array}{cc}
	\Delta \overline{ \ln S_{ijet+1}}-\sum_k \theta_{ke}\overline{S_{kejt}} \pi_{kjt}+\pi_{ijt} & l\leq N_1 \\
	1-\sum_k\theta_{ke}\overline{S_{kejt}}    & N_1<l\leq N_1+N_2	 \\
	\Delta  \left[\ln \frac{q_{ejt+1}}{q_{e'jt+1}}\right]-\beta_j\left[\sum_k\left(\theta_{ke} \overline{S_{kjet}}-\theta_{ke'} \overline{S_{kje' t}}\right)\pi_{kjt}\right]-\gamma_{e,e't} & N_1+N_2<l\leq N 
\end{array}\right.
\eeqns

\section{GMM standard errors}
The GMM estimates are distributed as:
\beqns
\sqrt{N}(\hat\mu-\mu)\rightarrow N(0,\tilde{V})
\eeqns
where $\bar{V}=(D'AD)^{-1}D'AVAD(D'AD)^{-1}$. Here:
\bitem
	\item $D$ is the model gradient.
	\item $V$ is defined as:
	\beqns
		V=\lim_{N\rightarrow\infty}\frac{1}{{N}}\sum_{i=1}^N\expect{\psi(w_i,\mu)\psi(w_i,\mu)'}{}
	\eeqns
	\item $A$ is the weighting matrix $(Z'Z)^{-1}$
\eitem
We estimate $\bar{V}$ as:
\beqns
	\hat{\bar{V}}=(\hat{D}'A\hat{D})^{-1}\hat{D}'A\hat{V}A\hat{D}(\hat{D}'A\hat{D})^{-1}
\eeqns
where:
\bitem 
	\item $\hat{V}=\frac{1}{{N}}\sum_{i=1}^N\psi(w_i,\hat{\mu})\psi(w_i,\hat{\mu})'$.
	\item $\hat{D}=\frac{1}{N}\sum_{i=1}^{N}\frac{\partial \psi(w_i,\hat{\mu})}{\partial c'}$
\eitem
\subsection{Computing the gradient:}
Let $\Xi$ be the $N\times R$ matrix with general term $\Xi_{lr}=\frac{\partial \varepsilon(w_l,c)}{\partial c_{r}}$. Then our estimate of the gradient is $P\times R$ matrix:
\beqns
\hat{D}=\frac{1}{N}Z'\Xi
\eeqns
Thus, we jut have to compute $\Xi_{lr}$. We need to compute derivatives with respect to four types of parameters: $\theta_{ke}$, $\pi_{kjt}$, and $\beta_j$:
\beqns
\frac{\partial \varepsilon_l(\mu)}{\partial \theta_{ie}}&=&\left\{\begin{array}{lc}
	- \overline{S_{kejt}} \pi_{ijt} & l\leq N_1, e=E(l), i\neq 1 \\
	-\overline{S_{iejt}}    & N_1<l\leq N_1+N_2,	e=E(l), i\neq 1 \\
	-\beta_j \overline{S_{ije t}}\pi_{ijt} & N_1+N_2<l\leq N, (e,\cdot,\cdot)=EET(l), i\neq 1\\
	\beta_j  \overline{S_{ije t}}\pi_{ijt} & N_1+N_2<l\leq N, (\cdot,e,\cdot)=EET(l), i\neq 1\\
	0 & \text{otherwise}
\end{array}\right.\\
\frac{\partial \varepsilon_l(\mu)}{\partial \theta_{1}}&=&\left\{\begin{array}{lc}
	- \overline{S_{kejt}} \pi_{ijt} & l\leq N_1\\
	-\overline{S_{iejt}}    & N_1<l\leq N_1+N_2\\
	\beta_j  \overline{S_{ije t}}\pi_{ijt} 	-\beta_j \overline{S_{ije' t}}\pi_{ijt} & N_1+N_2<l\leq N\\
	0 & \text{otherwise}
\end{array}\right.\\
\frac{\partial\varepsilon_l(\mu)}{\partial \pi_{ijt}}&=&\left\{\begin{array}{lc}
	- \theta_{ie}\overline{S_{iejt}} & l\leq N_1, i\neq I(l), j=J(l), t=T(l) \\
	- \theta_{ie}\overline{S_{iejt}}+1 & l\leq N_1, i= I(l),j=J(l), t=T(l) \\
	-\beta_j\left(\theta_{ie} \overline{S_{ijet}}-\theta_{ie'} \overline{S_{ije' t}}\right) & N_1+N_2<l\leq N \\
	0 & \text{otherwise}
\end{array}\right.\\
\frac{\partial\varepsilon_l(\mu)}{\partial \beta_j}&=&\left\{\begin{array}{lc}
	-\left[\sum_k\left(\theta_{ke} \overline{S_{kjet}}-\theta_{ke'} \overline{S_{kje' t}}\right)\pi_{kjt}\right] & N_1+N_2<l\leq N, j=J(l)\\
	0& \text{otherwise}
\end{array}\right.\\
\frac{\partial\varepsilon_l(\mu)}{\partial \gamma_{ee't}}&=&\left\{\begin{array}{lc}
	-1 & N_1+N_2<l\leq N, (e,e',t)=EET(l)\\
	0&  \text{otherwise}
\end{array}\right.\\
\eeqns
We compute $\Xi$ with the function {\tt get\_xi\_matrix}, and compute $\bar{V}$ with {\tt estimate\_v}. Finally, the function {\tt get\_standard\_errors} computes the standard errors.


\subsection{Standard errors for $\sigma_j$ and $d\ln A_{ijt}$}
The above derivation gives standard errors for $\beta_j=\frac{\sigma_j-1}{\sigma_j}$. Using the delta method, it is straightforward to compute standard errors for $\sigma_j=\frac{1}{1-\beta_j}$.
\beqns
	\sqrt{N}(\hat{\sigma_j}-\sigma_j)\rightarrow N\left(0,\text{var}(\sigma_j)\left[\frac{\partial \sigma_j}{\partial \beta_j }\right]^2\right)
\eeqns
where:
\beqns
	\left[\frac{\partial \sigma_j}{\partial \beta_j }\right]^2=\frac{1}{(1-\beta_j)^2}={\sigma_j^2}
\eeqns
By an analogous argument:
\beqns
\pi_{ijt}=\frac{\sigma_j}{\sigma_j-1}d\ln A_{ijt}
\eeqns
therefore:
\beqns
	d\ln A_{ijt}=\frac{\sigma_j-1}{\sigma_j}\pi_{ijt}=\beta_j\pi_{ijt}
\eeqns
\beqns
	\sqrt{N}(\hat{d\ln A_{ijt}}-d\ln A_{ijt})\rightarrow N\left(0,G(\gamma)'\tilde{V}G(\gamma)\right)
\eeqns
where $\tilde{V}$ is the variance matrix of $\psi=(\pi_{ijt},\beta_j)'$ and $	G(\psi)=(\beta_j, \pi_{ijt})'$


\newcommand{\txsp}{\hspace{3mm}}
\newcolumntype{P}[1]{>{\centering\arraybackslash}p{#1}}


\begin{adjustbox}{max width=1\textwidth}
\begin{threeparttable}[h!]
	%\cmidrule(lr){3-5}  \cmidrule(lr){6-8}\cmidrule(lr){9-10}
	\centering
	\caption{Summary statistics of teachers in the study sample}
\begin{tabular}{lrrrrrrr}
	\toprule
	\multicolumn{1}{P{8.41em}}{\textbf{Variable}} & \multicolumn{1}{P{6.225em}}{\textbf{Age arrival USA}} & \multicolumn{1}{P{6.225em}}{\textbf{Central FPs}} & \multicolumn{1}{P{6.225em}}{\textbf{Pronouns present}} & \multicolumn{1}{P{6.225em}}{\textbf{Preverbal pronouns}} & \multicolumn{1}{P{6.225em}}{\textbf{Preverbal subjects}} & \multicolumn{1}{P{6.225em}}{\textbf{s-deletion}} & \multicolumn{1}{P{6.225em}}{\textbf{Liquid-neutralization}} \\
	\midrule
	\textit{A. Puerto Rico} &   &   &   &   &   &   &  \\
	\txsp Pascal & 36 & 0 & 42.1 & 94.9 & 74.6 & 70.6 & 73 \\
	\txsp Priscila & 0 & 100 & 61.1 & 100 & 88.9 & 68 & 83 \\
	\midrule \txsp Observations &   & 150 & 421 & 222 & 96 & 150 & 168 \\
	\txsp $\chi^2$ test p-value &   & {***} & {***} & {**} &  {*} & {p =.72} & {p = .17} \\ 
	\midrule 
	\textit{B. El Salvador} \\
	\txsp Emilio & 20 & 32 & 29.7 & 78.7 & 44.1 & 16 & 0 \\
	\txsp Eduardo & 0 & 93 & 23.7 & 98.2 & 85.2 & 9 & 0 \\
	\midrule\txsp {Observations} &   & 60 & 479 & 129 & 86 & 150 & 52 \\
	\txsp {X2 test p-value} &   &  {***} & {p = .15} &  {***}  & {***} & {p = .31} &  {NA} \\
	\midrule 
	\textit{C. Colombia} &   &   &   &   &   &   &  \\
	\txsp Clemente & 30 & 18.9 & 25.5 & 94.7 & 89 & 14.4 & 12 \\
	\txsp Cesar & 3 & 70.8 & 30.1 & 95.3 & 89 & 6.4 & 4 \\
	\midrule\txsp{Observations} &   & 185 & 1,487 & 336 & 454 & 153 & 88 \\
	\txsp {$\chi^2$ test p-value} &   & {***} &  {*} &  {p =.78} & {p = .95} &{p = .11} & 24 \\
	\midrule\textit{D. Dominican Republic} &   &   &   &   &   &   &  \\
	\txsp David & 36 & 7.2 & 31.9 & 98 & 84 & 50.7 & 42 \\
	\txsp Donaldo & 4 & 92.4 & 63.5 & 100 & 84 & 26.3 & 31.7 \\
    \midrule \txsp {Observations} &   & 205 & 363 & 175 & 100 & 205 & 236 \\
	\txsp {$\chi^2$ test p-value} &   &{***} &{***} &{p = .11}  &{p = .99} &{***} &{p = .12} \\
	\midrule\textbf{Total observations} &   & 600 & 2750 & 862 & 736 & 658 & 544 \\
	\textbf{n sig. results} &   & 4 & 3 & 2 & 2 & 1 & 0 \\
	\bottomrule
	\bottomrule
\end{tabular}%
\begin{tablenotes}
	\item {\footnotesize \textit{Note:} $*=p<.05$, $**=p<.01$, $***=p<.001$ }
\end{tablenotes}
\end{threeparttable}
\end{adjustbox}
\end{document}

